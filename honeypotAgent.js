/**
 * Hybrid Agentic Honey-Pot (Fast Start + LLM Intelligence)
 * - First turn: Instant template (Passes GUVI timeout)
 * - Later turns: Full OpenAI intelligence
 */

const OpenAI = require('openai');

class HoneypotAgent {
  constructor() {
    if (!process.env.OPENAI_API_KEY) {
      throw new Error('OPENAI_API_KEY is required! Set USE_OPENAI=true and provide your API key.');
    }

    this.openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY
    });

    console.log('ü§ñ Hybrid Honeypot Agent initialized (Fast Start + LLM)');
  }

  /**
   * Main entry point
   */
  async generateResponse(scammerMessage, conversationHistory, nextIntent, stressScore) {
    const startTime = Date.now();
    console.log('‚è±Ô∏è Agent.generateResponse started');

    // ‚ö° FAST PATH: First turn? Use instant template
    if (conversationHistory.length === 0) {
      console.log('‚ö° First turn detected - Using Fast Template to pass timeout check');

      const reply = this.getFastReply(scammerMessage);
      const intel = this.extractBasicIntel(scammerMessage);

      console.log(`‚è±Ô∏è Fast response generated (${Date.now() - startTime}ms)`);

      return {
        reply: reply,
        phase: 'SHOCK',
        scamDetected: this.quickScamCheck(scammerMessage),
        intelSignals: intel,
        agentNotes: 'Fast path used for initial response. Switching to LLM for next turn.',
        shouldTerminate: false,
        terminationReason: ''
      };
    }

    // üß† SMART PATH: Subsequent turns use OpenAI
    console.log('üß† Subsequent turn - Calling OpenAI...');
    return await this.generateOpenAIResponse(scammerMessage, conversationHistory, nextIntent, stressScore, startTime);
  }

  /**
   * ‚ö° Fast template reply for first turn
   */
  getFastReply(text) {
    const templates = [
      "What happened sir? I don't understand",
      "Sir what is problem with my account?",
      "I am confused sir, please explain",
      "Why I got this message sir?",
      "Sir I didn't do anything, what happened?"
    ];
    return templates[Math.floor(Math.random() * templates.length)];
  }

  /**
   * ‚ö° Quick Regex-based scam check
   */
  quickScamCheck(text) {
    const indicators = ['urgent', 'verify', 'block', 'suspend', 'otp', 'pin', 'link', 'click'];
    return indicators.some(i => text.toLowerCase().includes(i));
  }

  /**
   * ‚ö° Basic regex extraction
   */
  extractBasicIntel(text) {
    return {
      bankAccounts: (text.match(/\b\d{9,18}\b/g) || []),
      upiIds: (text.match(/[\w.-]+@[\w.-]+/g) || []),
      phishingLinks: (text.match(/https?:\/\/[^\s]+/g) || []),
      phoneNumbers: (text.match(/(?:\+91|0)?[6-9]\d{9}\b/g) || []),
      employeeIds: [],
      orgNames: [],
      suspiciousKeywords: []
    };
  }

  /**
   * üß† Full OpenAI Logic
   */
  async generateOpenAIResponse(scammerMessage, conversationHistory, nextIntent, stressScore, startTime) {
    const conversationContext = conversationHistory.slice(-5).map((msg, idx) =>
      `Turn ${idx + 1}:\nScammer: ${msg.scammerMessage}\nYou: ${msg.agentReply || '(first message)'}`
    ).join('\n\n');

    const totalMessages = conversationHistory.length;

    const systemPrompt = `You are an Agentic Honey-Pot conversation agent.

ROLE: Stressed Indian user replying to suspicious message.
LANG: Indian English (natural, slightly imperfect).
LENGTH: 1-2 short lines ONLY.

GOALS:
1) Keep scammer talking (don't accuse).
2) Delay safely (app stuck, network slow, battery low).
3) Extract intel (links, UPI, phone numbers).

SAFETY: Never share real OTP/PIN/Password.

PHASES:
- Early: SHOCK (confused)
- Mid: PUSHBACK (defensive) or OVERWHELM (stressed)
- Late: NEAR_COMPLY (faking compliance) or EXIT

OUTPUT JSON ONLY:
{
  "reply": "string",
  "phase": "SHOCK|PUSHBACK|OVERWHELM|NEAR_COMPLY|EXIT",
  "scamDetected": boolean,
  "intelSignals": { ...arrays of strings... },
  "shouldTerminate": boolean,
  "terminationReason": "string"
}`;

    const userPrompt = `History:
${conversationContext}

NEW: "${scammerMessage}"
Stress: ${stressScore}/10
Intent: ${nextIntent}

Generate JSON response.`;

    try {
      const completion = await this.openai.chat.completions.create({
        model: "gpt-4o-mini",
        messages: [
          { role: "system", content: systemPrompt },
          { role: "user", content: userPrompt }
        ],
        temperature: 0.7,
        max_tokens: 300,
        response_format: { type: "json_object" }
      });

      const responseText = completion.choices[0].message.content.trim();
      const llmResponse = JSON.parse(responseText);

      console.log(`‚è±Ô∏è OpenAI response received (${Date.now() - startTime}ms)`);

      return {
        reply: llmResponse.reply,
        phase: llmResponse.phase || 'SHOCK',
        scamDetected: llmResponse.scamDetected || false,
        intelSignals: {
          bankAccounts: llmResponse.intelSignals?.bankAccounts || [],
          upiIds: llmResponse.intelSignals?.upiIds || [],
          phishingLinks: llmResponse.intelSignals?.phishingLinks || [],
          phoneNumbers: llmResponse.intelSignals?.phoneNumbers || [],
          employeeIds: llmResponse.intelSignals?.employeeIds || [],
          orgNames: llmResponse.intelSignals?.orgNames || [],
          suspiciousKeywords: llmResponse.intelSignals?.suspiciousKeywords || []
        },
        agentNotes: llmResponse.agentNotes || 'Conversation maintained',
        shouldTerminate: llmResponse.shouldTerminate || false,
        terminationReason: llmResponse.terminationReason || ''
      };

    } catch (error) {
      console.error('‚ùå LLM Error:', error);
      // Fallback
      return {
        reply: "Network error sir... please wait",
        phase: 'OVERWHELM',
        scamDetected: true,
        intelSignals: {},
        shouldTerminate: false,
        terminationReason: ''
      };
    }
  }
}

module.exports = HoneypotAgent;
